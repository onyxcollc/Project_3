{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports \n",
    "\n",
    "#Reddit API import\n",
    "from psaw import PushshiftAPI\n",
    "#import config\n",
    "#import psycopg2\n",
    "import datetime \n",
    "#import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection = psycopg2.connect(host=config.DB_HOST, database=config.DB_NAME, user=config.DB_USER, password=config.DB_PASS)\n",
    "\n",
    "#cursor = connection.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "#cursor.execute(\"\"\"\"\n",
    "    #SELECT * FROM stock\n",
    "#\"\"\")\n",
    "#rows = cursor.fetchall()\n",
    "#print(rows)\n",
    "\n",
    "#stocks = {}\n",
    "#for row in rows:\n",
    "   #  stocks['$'+ row['symbol']] = row ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f2cb348a0785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreddit_fetched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mcompound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compound\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analyzer' is not defined"
     ]
    }
   ],
   "source": [
    "start_time= int (datetime.datetime(2021 , 3 , 2).timestamp())\n",
    "\n",
    "submissions = list(api.search_submissions(after=start_time,\n",
    "                            subreddit='wallstreetbets',\n",
    "                            filter=['url','author', 'title', 'subreddit']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for submission in submissions:\n",
    "       \n",
    "        \n",
    "        \n",
    "    try:\n",
    "            sentiment = analyzer.polarity_scores(reddit_fetched)\n",
    "            compound = sentiment[\"compound\"]\n",
    "            \n",
    "            df.loc[x, \"compound\"] = compound\n",
    "            x+=1  \n",
    "            \n",
    "            \n",
    "    except AttributeError:\n",
    "            pass\n",
    "return df\n",
    "\n",
    "\n",
    "def get_avg_reddit_sentiment(ticker, search_word):\n",
    "\n",
    "    # tweepy variables\n",
    "    # search_word = search_word\n",
    "    date_since = \"2021-03-02\"\n",
    "    items = 1\n",
    "    reddit_search_phrase = search_word + \" OR \" + \"$\" + ticker\n",
    "\n",
    "    # call the reddit sentiment function and return a dataframe\n",
    "    reddit_df = get_reddit_sentiment(reddit_search_phrase, date_since, items)\n",
    "\n",
    "    avg_sentiment = tweets_df[\"compound\"].mean()#.dropna()\n",
    "    \n",
    "    return avg_sentiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(submission.created_utc)\n",
    "    #print(submission.title)\n",
    "    #print(submission.url)\n",
    "    \n",
    "    words = submission.title.split()\n",
    "    cash_tags = list(set(filter(lambda word: word.lower().startswith('$'), words)))\n",
    "    \n",
    "    if len(cash_tags) > 0:\n",
    "        print(cash_tags)\n",
    "        #print(submission.created_utc)\n",
    "        print(submission.title)\n",
    "        #print(submission.url)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
