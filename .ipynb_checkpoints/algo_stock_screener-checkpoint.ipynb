{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Authentication Verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Kris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Importing initial Notebooks and Libraries\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# Jupyter notebook imports\n",
    "%run twitter_sentiment.ipynb\n",
    "\n",
    "# Library imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import alpaca_trade_api as tradeapi\n",
    "from talib import RSI, OBV, ATR, STDDEV\n",
    "\n",
    "# Load .env enviroment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    API Authentications for Alpaca\n",
    "\"\"\"\n",
    "############################################################\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version = \"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicators(symbol, security):   \n",
    "\n",
    "    indicator_scores = []\n",
    "    # column_names = ['symbol']\n",
    "    indicator_scores = pd.DataFrame() #columns = column_names)\n",
    "    \n",
    "    # Set timeframe to 15 Minutes\n",
    "    timeframe = \"15Min\"\n",
    "    \n",
    "    # Set end date to now for latest data\n",
    "    end_date = pd.Timestamp.now(tz=\"America/New_York\").isoformat()\n",
    "    \n",
    "    # set limit to past 100 15-minute intervals (equal to two trading days of 6.5 hours)\n",
    "    limit = 100\n",
    "        \n",
    "    #fetch ticker data \n",
    "    ticker_data = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit,\n",
    "        end=end_date\n",
    "        )[ticker]._raw\n",
    "    ticker_data_df = pd.DataFrame(data=ticker_data)\n",
    "    \n",
    "    ############################################################\n",
    "    \"\"\" \n",
    "        Volatility - Average True Range\n",
    "        Finds volatile stocks using ATR.\n",
    "        Looks for stocks that typically move more than 5% per day, based on a 50 time period average, \n",
    "        \n",
    "        Relative strength suggests continued outperformance while relative weakness suggests continued underperformance.\n",
    "        High RSI (usually above 70) may indicate a stock is overbought, therefore it is a sell signal. \n",
    "        Low RSI (usually below 30) indicates stock is oversold, which means a buy signal. \n",
    "        \n",
    "        On-balance volume (OBV) is a technical trading momentum indicator that \n",
    "        uses volume flow to predict changes in stock price.\n",
    "        \n",
    "        When both price and OBV are making higher peaks and higher troughs, \n",
    "        the upward trend is likely to continue.\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "    \n",
    "    #fetch Average True Range(ATR) volatility indicator\n",
    "    #average_true_range = pd.DataFrame(ATR(ticker_data_df['h'], ticker_data_df['l'], ticker_data_df['c'], timeperiod=14))\n",
    "\n",
    "    #fetch Standard Deviation volatility indicator\n",
    "    #std_dev = pd.DataFrame(STDDEV(ticker_data_df['c'], timeperiod=5, nbdev=1))\n",
    "    std_dev = pd.DataFrame(ticker_data_df['c']).std()\n",
    "    std_dev = std_dev.mean()\n",
    "                           \n",
    "    #Fetch RSI score\n",
    "    rsi_score = pd.DataFrame(RSI(ticker_data_df['c'], timeperiod=14))\n",
    "    #rsi_score = rsi_score.mean()\n",
    "    rsi_score = rsi_score.loc[(len(rsi_score)-1), 0]\n",
    "     \n",
    "    #Fetch On Balance Volume(OBV)\n",
    "    obv_score = pd.DataFrame(OBV(ticker_data_df['c'], ticker_data_df['v']))\n",
    "    \n",
    "    if (rsi_score <= 45) and (std_dev > 0.001):\n",
    "    \n",
    "        # if all conditions met, appends scores to dataframe\n",
    "        # Set the symbol row and column\n",
    "\n",
    "        indicator_scores.loc[0, 'symbol'] = symbol\n",
    "        indicator_scores.loc[0, 'security'] = security\n",
    "        indicator_scores.loc[0, 'std_dev'] = std_dev                    \n",
    "        #indicator_scores.loc[0, 'avg_true_range'] = average_true_range.loc[(len(average_true_range)-1), 0]\n",
    "        indicator_scores.loc[0, 'on_balance_volume'] = obv_score.loc[(len(obv_score)-1), 0]\n",
    "        indicator_scores.loc[0, 'relative_strength_index'] = rsi_score\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return indicator_scores\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Function that fetches the Twitter Sentiment score from twitter_sentiment.ipynb\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def fetch_twitter_sentiment(ticker, search_word):\n",
    "    score = compound_twitter_sentiment(ticker, search_word)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_screener():\n",
    "\n",
    "    ############################################################\n",
    "    \"\"\"\n",
    "        Scrapes Wikipedia and pulls stock data for every ticker symbol on the S&P500\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "    \n",
    "    # scrapes the wikipedia page relating to the S&P 500 and returns a list of DataFrame objects\n",
    "    table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    \n",
    "    # Since we are only interested in the current list of stocks in the S&P 500, we only need the DataFrame object at index 0\n",
    "    sp500_list_df = table[0]\n",
    "    sp500_tickers = sp500_list_df[[\"Symbol\", \"Security\"]]\n",
    "    \n",
    "    ############################################################\n",
    "    \"\"\"\n",
    "        Stock Screener for Day Trading\n",
    "        Start Main Function\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "    \n",
    "    # Initialize the dataframe and set the columns\n",
    "    indicators_df = []\n",
    "    column_names = ['symbol', 'security', 'std_dev', 'on_balance_volume', 'relative_strength_index']\n",
    "    indicators_df = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    # for loop iterates through all tickers in S&P 500\n",
    "    for tickers in range(len(sp500_tickers[\"Symbol\"])):\n",
    "        \n",
    "        # set the current ticker symbol and company security name\n",
    "        company = sp500_tickers.loc[[tickers][0]]\n",
    "        ticker = company.Symbol\n",
    "        security = company.Security\n",
    "        \n",
    "        # Set timeframe to 1 Day to capture daily Volume total\n",
    "        timeframe = \"1D\"\n",
    "        \n",
    "        # Set the limit of bars to just the previous time period\n",
    "        limit = 1\n",
    "    \n",
    "        # Set end date to now for latest data (if run before market open to fetch yesterdays close)\n",
    "        end_date = pd.Timestamp.now(tz=\"America/New_York\").isoformat()\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\"    \n",
    "        \n",
    "        *** Notes on how to iterate over a barset object from Alpaca ***\n",
    "        \n",
    "        # Set timeframe to 15 Minutes\n",
    "        timeframe = \"15Min\"\n",
    "        #fetch ticker data \n",
    "        ticker_data = api.get_barset(\n",
    "            ticker,\n",
    "            timeframe,\n",
    "            limit,\n",
    "            end=end_date\n",
    "            )\n",
    "            \n",
    "        # ticker_data inherits dict and bars inherits list. You can iterate over them accordingly: \n",
    "        for symbols in ticker_data:\n",
    "            bars = ticker_data[symbols]\n",
    "            for bar in bars:\n",
    "                sp500_ticker_data.loc[symbols, 'time'] = bar.t\n",
    "                sp500_ticker_data.loc[symbols, 'open'] = bar.o\n",
    "                sp500_ticker_data.loc[symbols, 'low'] = bar.l\n",
    "                sp500_ticker_data.loc[symbols, 'high'] = bar.h\n",
    "                sp500_ticker_data.loc[symbols, 'close'] = bar.c\n",
    "                sp500_ticker_data.loc[symbols, 'volume'] = bar.v\n",
    "                \n",
    "        \"\"\"\n",
    "        ############################################################ \n",
    "        \n",
    "        # Initial pass of ticker symbols\n",
    "        # fetch last daily barset object for ticker and put raw data into dataframe\n",
    "        bar_set = api.get_barset(\n",
    "            ticker,\n",
    "            timeframe,\n",
    "            limit,\n",
    "            end=end_date\n",
    "            )[ticker]._raw\n",
    "        initial_check = pd.DataFrame(data=bar_set)\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\"\n",
    "        # Since Day traders generally look for stocks that have at least 1 million shares traded daily, \n",
    "        # this checks to see if the daily volume for current ticker >= 1Million.\n",
    "        # This also checks the last closing price of a ticker to see if it is below $1 or above $100.\n",
    "        # If ticker volume < 1M or it's last closing price was above $100, \n",
    "        # we stop this iteration and continue to the next iteration of the loop.\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "               \n",
    "        if (initial_check.loc[0, 'v'] <= 1000000) or (initial_check.loc[0, 'c'] > 100) or (initial_check.loc[0, 'c'] < 1):\n",
    "            continue\n",
    "        else:\n",
    "            # If the ticker passes initial checks, it continues to calculating the additional indicators\n",
    "            \n",
    "            indicators_df = indicators_df.append(get_indicators(ticker, security), ignore_index=True)\n",
    "            \n",
    "    ############################################################\n",
    "    \"\"\" \n",
    "        Twitter and Reddit Compound Sentiment\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "        \n",
    "    for stocks in range(len(indicators_df[\"symbol\"])):\n",
    "        \n",
    "        ticker = indicators_df.loc[stocks, \"symbol\"]\n",
    "        security = indicators_df.loc[stocks, \"security\"]\n",
    "        \n",
    "        #fetches the Compound Sentiment score for the last 15 minutes of Tweets on Twitter\n",
    "        twitter_comp_sentiment_score = fetch_twitter_sentiment(ticker, security)\n",
    "        indicators_df.loc[stocks, 'twitter_sentiment'] = twitter_comp_sentiment_score\n",
    "            \n",
    "        #fetch reddit sentiment\n",
    "        #reddit_sentiment = fetch_reddit_sentiment(ticker, security)\n",
    "        #indicators_df.loc[x, 'reddit_sentiment'] = reddit_sentiment\n",
    "    \n",
    "    \n",
    "        \n",
    "    ############################################################\n",
    "    \"\"\" \n",
    "    \n",
    "        We want a stock that scores low on the RSI (oversold) and high on the Social Sentiment (people are talking good about it, may signal an uptrend).\n",
    "        This calulates the score for RSI - (Total Social Sentiment * 100) and returns a sorted dataframe with Top 5 stock tickers (in this case, the 5 lowest scores in ascending order).\n",
    "        We multiply the Total Social Sentiment by 100 to scale it for RSI.\n",
    "        \n",
    "    \"\"\"\n",
    "    ############################################################    \n",
    "        \n",
    "    # adds up sentiment indicator column scores and calculates the total_indi_score\n",
    "    for symbol in range(len(indicators_df[\"symbol\"])):\n",
    "        indicators_df.loc[symbol, 'total_screener_score'] = (indicators_df.loc[symbol, 'relative_strength_index'] - (indicators_df.loc[symbol, 'twitter_sentiment'] * 100)) # + indicators_df.loc[rows, 'reddit_sentiment'])\n",
    "    \n",
    "    # sets the index to the ticker symbol and sorts indidcator_df by score\n",
    "    indicators_df.set_index('symbol', inplace=True)\n",
    "    indicators_df.sort_values(by='total_screener_score', inplace=True)\n",
    "    \n",
    "    # saves top 5 tickers into dataframe\n",
    "    top5_stocks_df = indicators_df[:5]\n",
    "    top5 = pd.DataFrame(data = top5_stocks_df.index)\n",
    "\n",
    "    \n",
    "    # return top 5 stock recommendations\n",
    "    return top5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/15Min 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "Rate limit reached. Sleeping for: 848\n",
      "Rate limit reached. Sleeping for: 851\n",
      "Rate limit reached. Sleeping for: 850\n",
      "Rate limit reached. Sleeping for: 854\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 503",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-50dd20af7b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_screener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-03d0f80f98da>\u001b[0m in \u001b[0;36mstock_screener\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m#fetches the Compound Sentiment score for the last 15 minutes of Tweets on Twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mtwitter_comp_sentiment_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mindicators_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'twitter_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_comp_sentiment_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-7cd05ccb2b7a>\u001b[0m in \u001b[0;36mfetch_twitter_sentiment\u001b[0;34m(ticker, search_word)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompound_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-b012d279c16c>\u001b[0m in \u001b[0;36mcompound_twitter_sentiment\u001b[0;34m(ticker, search_word)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompound_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mlatest_twitter_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_avg_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mtwitter_sentiment_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_twitter_sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-b012d279c16c>\u001b[0m in \u001b[0;36mget_avg_twitter_sentiment\u001b[0;34m(ticker, search_word)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# call the twitter sentiment function and return a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_twitter_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_search_phrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_since\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mavg_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compound\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-b012d279c16c>\u001b[0m in \u001b[0;36mget_twitter_sentiment\u001b[0;34m(search_word, date_since, items)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     ).items(items)\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: Twitter error response: status code = 503"
     ]
    }
   ],
   "source": [
    "\n",
    "top5 = stock_screener()\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
