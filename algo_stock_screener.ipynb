{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Authentication Verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Kris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Importing initial Notebooks and Libraries\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# Jupyter notebook imports\n",
    "%run twitter_sentiment.ipynb\n",
    "\n",
    "# Library imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import alpaca_trade_api as tradeapi\n",
    "from talib import RSI, OBV\n",
    "\n",
    "# Load .env enviroment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    API Authentications for Alpaca\n",
    "\"\"\"\n",
    "############################################################\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version = \"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/1D 3 more time(s)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>obv</th>\n",
       "      <th>volatility</th>\n",
       "      <th>twitter_sentiment</th>\n",
       "      <th>reddit_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, open, low, close, volume, rsi, obv, volatility, twitter_sentiment, reddit_sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\"\n",
    "    Function scrapes Wikipedia and pulls stock data for every ticker symbol on the S&P500\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# scrapes the wikipedia page relating to the S&P 500 and returns a list of DataFrame objects\n",
    "table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "# Since we are only interested in the current list of stocks in the S&P 500, we only need the DataFrame object at index 0\n",
    "sp500_list_df = table[0]\n",
    "sp500_tickers = sp500_list_df[[\"Symbol\", \"Security\"]]\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Function that fetches the Twitter Sentiment score\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "def fetch_twitter_sentiment(ticker, search_word):\n",
    "    score = compound_twitter_sentiment(ticker, search_word)\n",
    "    return score\n",
    "\n",
    "############################################################\n",
    "\"\"\"\n",
    "    Stock Screener for Day Trading\n",
    "    Start Main Function\n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "# Initialize the dataframe and set the columns\n",
    "sp500_ticker_data = []\n",
    "column_names = ['time', 'open', 'low', 'close', 'volume', 'rsi', 'obv', 'volatility', 'twitter_sentiment', 'reddit_sentiment']\n",
    "sp500_ticker_data = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# for loop iterates through all tickers in S&P 500\n",
    "for tickers in range(len(sp500_tickers[\"Symbol\"])):\n",
    "    \n",
    "    # set the current ticker symbol then increases x by 1 \n",
    "    company = sp500_tickers.loc[[tickers][0]]\n",
    "    ticker = company.Symbol\n",
    "    security = company.Security\n",
    "    \n",
    "    # Set timeframe to 1 Day to capture daily Volume total\n",
    "    timeframe = \"1D\"\n",
    "    \n",
    "    # Set the limit of bars to just the previous time period\n",
    "    limit = 1\n",
    "\n",
    "    # Set end date to now for latest data (if run before market open to fetch yesterdays close)\n",
    "    end_date = pd.Timestamp.now(tz=\"America/New_York\").isoformat()\n",
    "    \n",
    "    # Initial pass of ticker symbols\n",
    "    # fetch last daily barset object for ticker and put raw data into dataframe\n",
    "    bar_set = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit,\n",
    "        end=end_date\n",
    "        )[ticker]._raw\n",
    "    initial_check = pd.DataFrame(data=bar_set)\n",
    "    \n",
    "    ############################################################\n",
    "    \"\"\"\n",
    "    # Since Day traders generally look for stocks that have at least 1 million shares traded daily, \n",
    "    # this checks to see if the daily volume for current ticker >= 1Million.\n",
    "    # This also checks the last closing price of a ticker to see if it is above $100.\n",
    "    # If ticker volume < 1M or it's last closing price was above $100, \n",
    "    # we stop this iteration and continue to the next iteration of the loop.\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "        \n",
    "    if initial_check.loc[0, 'v'] <= 1000000 or initial_check.loc[0, 'c'] > 100:\n",
    "        continue\n",
    "    else:\n",
    "        # If the ticker passes both initial checks, it continues to calculating the additional indicators\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\"         \n",
    "        \n",
    "        # Set timeframe to 15 Minutes\n",
    "        timeframe = \"15Min\"\n",
    "    \n",
    "        #fetch ticker data \n",
    "        ticker_data = api.get_barset(\n",
    "            ticker,\n",
    "            timeframe,\n",
    "            limit,\n",
    "            end=end_date\n",
    "            )\n",
    "    \n",
    "        #ticker_data inherits dict and bars inherits list. You can iterate over them accordingly\n",
    "        for symbols in ticker_data:\n",
    "            bars = ticker_data[symbols]\n",
    "            for bar in bars:\n",
    "                sp500_ticker_data.loc[symbols, 'time'] = bar.t\n",
    "                sp500_ticker_data.loc[symbols, 'open'] = bar.o\n",
    "                sp500_ticker_data.loc[symbols, 'low'] = bar.l\n",
    "                sp500_ticker_data.loc[symbols, 'close'] = bar.c\n",
    "                sp500_ticker_data.loc[symbols, 'volume'] = bar.v\n",
    "\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Relative strength suggests continued outperformance while relative weakness suggests continued underperformance.\n",
    "            High RSI (usually above 70) may indicate a stock is overbought, therefore it is a sell signal. \n",
    "            Low RSI (usually below 30) indicates stock is oversold, which means a buy signal. \n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #Fetch RSI score\n",
    "        #rsi_score = RSI(sp500_ticker_data.loc[tickers, 'close'], timeperiod=1)\n",
    "        #sp500_ticker_data.loc[tickers, 'rsi'] = rsi_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            On-balance volume (OBV) is a technical trading momentum indicator that \n",
    "            uses volume flow to predict changes in stock price.\n",
    "            \n",
    "            When both price and OBV are making higher peaks and higher troughs, \n",
    "            the upward trend is likely to continue.\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #Fetch On Balance Volume(OBV)\n",
    "        #obv_score = OBV(sp500_ticker_data.loc[tickers, 'close'], sp500_ticker_data.loc[tickers, 'volume'])\n",
    "        #sp500_ticker_data.loc[tickers, 'obv'] = obv_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Volatility\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        # Fetch previos day data and calculate .std() ??\n",
    "        #fetch Average True Range(ATR) volatility indicator\n",
    "        #\n",
    "        #atr_score = ATR(high, low, close, timeperiod=14)\n",
    "        #sp500_ticker_data.loc[tickers, 'atr'] = atr_score\n",
    "        \n",
    "        ############################################################\n",
    "        \"\"\" \n",
    "            Twitter and Reddit Compound Sentiment\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        \n",
    "        #fetches the Compound Sentiment score for the last 15 minutes of Tweets on Twitter\n",
    "        #twitter_comp_sentiment_score = fetch_twitter_sentiment(ticker, security)\n",
    "        #sp500_ticker_data.loc[tickers, 'twitter_sentiment'] = twitter_comp_sentiment_score\n",
    "        \n",
    "        #fetch reddit sentiment\n",
    "        #reddit_sentiment = fetch_reddit_sentiment(ticker)\n",
    "        #sp500_ticker_data.loc[x, 'reddit_sentiment'] = reddit_sentiment\n",
    "    \n",
    "sp500_ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 'rsi')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 'rsi')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ff7fb35309df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# adds up all indicator column scores and calculates the total_indi_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicators_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_trading_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rsi'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obv'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volatility'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'twitter_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindicators_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reddit_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# sorts indidcator_df by total_indie_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlpenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 'rsi')"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "\"\"\" \n",
    "\n",
    "    Adds up scores of each indicator and returns a sorted list with Top 5 stock tickers\n",
    "    \n",
    "\"\"\"\n",
    "############################################################\n",
    "\n",
    "indicators_df = pd.DataFrame(sp500_ticker_data)\n",
    "\n",
    "# adds up all indicator column scores and calculates the total_indi_score\n",
    "for rows in range(len(indicators_df)):\n",
    "    indicators_df[rows, 'total_trading_score'] = float(indicators_df[rows, 'rsi'] + indicators_df[rows, 'obv'] + indicators_df[rows, 'volatility'] + indicators_df[rows, 'twitter_sentiment'] + indicators_df[rows, 'reddit_sentiment'])\n",
    "    \n",
    "# sorts indidcator_df by total_indie_score\n",
    "indicators_df.sort_by(by='total_trading_score', ascending=True)\n",
    "\n",
    "# saves top 5 tickers into top5_stocks_df[\"tickers\"]\n",
    "top5_stocks_df = indicators_df[:4]\n",
    "\n",
    "# return top 5 stock recommendations\n",
    "top5_stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
